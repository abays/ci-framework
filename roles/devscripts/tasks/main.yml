---
# Copyright Red Hat, Inc.
# All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may
# not use this file except in compliance with the License. You may obtain
# a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
# License for the specific language governing permissions and limitations
# under the License.

- name: Build configuration
  tags:
    - always
  ansible.builtin.include_tasks:
    file: build_config.yml
    apply:
      tags:
        - always

- name: Check and prepare the environment
  tags:
    - always
  ansible.builtin.import_tasks: 100_pre.yml

- name: Deploy OpenShift cluster
  tags:
    - devscripts_deploy
    - bootstrap
  when:
    - not cifmw_devscripts_dry_run | bool
    - >-
      (
        not (
          (cifmw_devscripts_ocp_comply | bool) or
          (cifmw_devscripts_ocp_online | bool)
        )
      )
  vars:
    _log_src: >-
      {{
        (cifmw_devscripts_repo_dir, 'logs' ) | path_join
      }}
  block:
    - name: Do workaround when SNO set
      when: cifmw_devscripts_sno
      block:
        - name: Copy workaround script
          ansible.builtin.copy:
            content: |
              TARGET="192.168.111.2"
              MAX_FAILURES=10
              FAILURES=0
              while true; do
                  if ping -c1 -W1 "$TARGET" > /dev/null 2>&1; then
                      echo "bootstrap in progress..."
                      sleep 1
                  else
                      FAILURES=$FAILURES+1
                  fi

                  if [[ $FAILURES -ge $MAX_FAILURES ]]; then
                      echo "Bootstrap probably is completed. Continue..."
                      break
                  fi

                  sleep 1
              done

              if [ -f /etc/NetworkManager/dnsmasq.d/openshift-ocp.conf ]; then
                  if grep -q '192.168.111.2' /etc/NetworkManager/dnsmasq.d/openshift-ocp.conf ; then
                      sudo sed -i 's/192.168.111.2/192.168.111.10/g' /etc/NetworkManager/dnsmasq.d/openshift-ocp.conf;
                  fi;
                  if grep -q '192.168.111.3' /etc/NetworkManager/dnsmasq.d/openshift-ocp.conf ; then
                      sudo sed -i 's/192.168.111.3/192.168.111.4/g' /etc/NetworkManager/dnsmasq.d/openshift-ocp.conf;
                  fi;
              fi

              # hypervisor - cifmw-dnsmasq
              sudo find /etc/cifmw-dnsmasq.d -type f -exec sed -i 's/192.168.111.2/192.168.111.10/g' {} \;
              sudo find /etc/cifmw-dnsmasq.d -type f -exec sed -i 's/192.168.111.3/192.168.111.4/g' {} \;

              # dig apps.ocp.openstack.lab => 192.168.111.4
              # dig api.ocp.openstack.lab  => 192.168.111.10

              ssh-keyscan -H 192.168.111.10 >> {{ ansible_user_dir }}/.ssh/known_hosts

              # /etc/hosts
              ssh -i {{ ansible_user_dir }}/ci-framework-data/artifacts/cifmw_ocp_access_key \
                  core@192.168.111.10 \
                  bash -c "echo '192.168.111.10 api-int.ocp.openstack.lab api.ocp.openstack.lab' | sudo tee -a /etc/hosts"

              ssh -i {{ ansible_user_dir }}/ci-framework-data/artifacts/cifmw_ocp_access_key \
                  core@192.168.111.10 \
                  bash -c "echo '192.168.111.4 apps.ocp.openstack.lab' | sudo tee -a /etc/hosts"

              # Coredns
              ssh -i {{ ansible_user_dir }}/ci-framework-data/artifacts/cifmw_ocp_access_key \
                  core@192.168.111.10 sudo sed -i 's/192.168.111.2/192.168.111.10/g' /etc/coredns/Corefile

              ssh -i {{ ansible_user_dir }}/ci-framework-data/artifacts/cifmw_ocp_access_key \
                  core@192.168.111.10 sudo sed -i 's/192.168.111.3/192.168.111.4/g' /etc/coredns/Corefile

              # workaround for missing docker dir
              ssh -i {{ ansible_user_dir }}/ci-framework-data/artifacts/cifmw_ocp_access_key \
                  core@192.168.111.10 sudo mkdir -p /etc/docker

              sudo systemctl restart cifmw-dnsmasq
              sleep 5

              export KUBECONFIG={{ ansible_user_dir }}/src/github.com/openshift-metal3/dev-scripts/ocp/ocp/auth/kubeconfig

              # Add missing puzzle for ingress. Without that, openshift-ingress-operator
              # would be crashing (it is waiting for openshift-ingress router)
              oc apply -f https://raw.githubusercontent.com/openshift/router/refs/heads/master/deploy/route_crd.yaml

              oc -n openshift-dns rollout restart daemonsets dns-default
              oc -n openshift-dns rollout restart daemonsets node-resolver

              sleep 120

            dest: "{{ cifmw_devscripts_repo_dir }}/07-sno-workaround.sh"

        - name: Add the workaround script execution into 06_create_cluster.sh script
          ansible.builtin.replace:
            path: "{{ cifmw_devscripts_repo_dir }}/06_create_cluster.sh"
            regexp: '^create_cluster \${OCP_DIR}'
            replace: |
              #
              # NOTE(dpawlik): Right now, quit 06_create_cluster.sh, otherwise
              # it will get timeout from devscript role.
              # The value is set to 25 min and should be enough to deploy,
              # but if not, you can increase to more.
              #
              timeout {{ cifmw_devscripts_sno_bootstrap_timeout | default(1800) }} bash -c "source utils.sh && create_cluster ${OCP_DIR}" || true
              bash -x 07-sno-workaround.sh
              exit 0

    - name: Run devscripts make all
      cifmw.general.ci_script:
        chdir: "{{ cifmw_devscripts_repo_dir }}"
        output_dir: "{{ cifmw_devscripts_artifacts_dir }}"
        script: "timeout {{ cifmw_devscripts_installer_timeout }} make all"
  always:
    - name: Gather logs
      register: _deploy_logs
      ansible.builtin.find:
        paths: "{{ _log_src }}"
        patterns: "*.log"

    - name: Copy all generated logs
      ansible.builtin.copy:
        dest: "{{ cifmw_devscripts_logs_dir }}/{{ item.path | basename }}"
        remote_src: true
        src: "{{ item.path }}"
        mode: "0644"
      loop: "{{ _deploy_logs.files }}"
      loop_control:
        label: "{{ item.path }}"

- name: Executing dev-scripts post-install tasks.
  when:
    - not cifmw_devscripts_dry_run | bool
  ansible.builtin.include_tasks: 300_post.yml
